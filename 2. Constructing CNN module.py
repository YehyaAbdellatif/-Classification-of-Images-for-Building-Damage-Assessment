# -*- coding: utf-8 -*-
"""final proj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BVhtQc69PKd806VxnGwaArkH7nykRFt5

#Creating Convlution Layers, Augmunting the Data, and Compiling the Model
"""

model1 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),padding="same", activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding="same", activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding="same", activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),

    tf.keras.layers.Dense(3,activation='softmax')

])
model2 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),
    
    tf.keras.layers.Dense(2,activation='softmax')

])

model3 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),
    
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),

    tf.keras.layers.Dense(2,activation='softmax')

    
])
model4 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),

    tf.keras.layers.Dense(2,activation='softmax')

])
model5 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),

    tf.keras.layers.Dense(3,activation='softmax')

])
model6 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),

    tf.keras.layers.Dense(4,activation='softmax')

])
model7 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.5),

    tf.keras.layers.Dense(4,activation='softmax')

])
model8 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal',input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5),padding='same', activation='relu', kernel_initializer='normal'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding="valid"),
    tf.keras.layers.BatchNormalization(axis=-1),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='tanh', kernel_initializer='normal'),
    tf.keras.layers.BatchNormalization() ,
    tf.keras.layers.Dropout(rate=0.1),

    tf.keras.layers.Dense(4,activation='softmax')

])
learning_rate = 0.0001
epochs=150
opt= tf.keras.optimizers.Adam(learning_rate=learning_rate , decay=learning_rate/(epochs*0.5))
model1.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model2.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model3.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model4.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model5.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model6.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model7.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
model8.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
aug = tf.keras.preprocessing.image.ImageDataGenerator(
          rescale=1./255,
          rotation_range=40,
          width_shift_range=0.2,
          height_shift_range=0.2,
          zoom_range=0.3,
          shear_range=0.2,
          horizontal_flip=True,
          vertical_flip=True,
          fill_mode='nearest'
          )

"""#Fitting the Models Independently"""

history1 = model1.fit(aug.flow(X_train1, y_train1),validation_data = (X_val1, y_val1), epochs=epochs, shuffle=True)

history2 = model2.fit(aug.flow(X_train2, y_train2),validation_data = (X_val2, y_val2), epochs=epochs, shuffle=True)

history3 = model3.fit(aug.flow(X_train3, y_train3),validation_data = (X_val3, y_val3), epochs=epochs, shuffle=True)

history4 = model4.fit(aug.flow(X_train4, y_train4),validation_data = (X_val4, y_val4), epochs=epochs, shuffle=True)

history5 = model5.fit(aug.flow(X_train5, y_train5),validation_data = (X_val5, y_val5), epochs=200, shuffle=True)

history6 = model6.fit(aug.flow(X_train6, y_train6),validation_data = (X_val6, y_val6), epochs=epochs, shuffle=True)

history7 = model7.fit(aug.flow(X_train7, y_train7),validation_data = (X_val7, y_val7), epochs=epochs, shuffle=True)

history8 = model8.fit(aug.flow(X_train8, y_train8),validation_data = (X_val8, y_val8), epochs=epochs, shuffle=True)

"""#Plotting the Accuracy and Loss"""

plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history4.history['accuracy'])
plt.plot(history4.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history4.history['loss'])
plt.plot(history4.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history5.history['accuracy'])
plt.plot(history5.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history5.history['loss'])
plt.plot(history5.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history6.history['accuracy'])
plt.plot(history6.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history6.history['loss'])
plt.plot(history6.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history7.history['accuracy'])
plt.plot(history7.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history7.history['loss'])
plt.plot(history7.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history8.history['accuracy'])
plt.plot(history8.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(history8.history['loss'])
plt.plot(history8.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""#Predicting the Model"""

y_pred1=model1.predict(X_test1)
y_pred2=model2.predict(X_test2)
y_pred3=model3.predict(X_test3)
y_pred4=model4.predict(X_test4)
y_pred5=model5.predict(X_test5)
y_pred6=model6.predict(X_test6)
y_pred7=model7.predict(X_test7)
y_pred8=model8.predict(X_test8)

score = model1.evaluate(X_test1, y_test1, verbose=0)
print('Accuracy over the test set 1: \n ', round((score[1]*100), 2), '%')
score = model2.evaluate(X_test2, y_test2, verbose=0)
print('Accuracy over the test set 2: \n ', round((score[1]*100), 2), '%')
score = model3.evaluate(X_test3, y_test3, verbose=0)
print('Accuracy over the test set 3: \n ', round((score[1]*100), 2), '%')
score = model4.evaluate(X_test4, y_test4, verbose=0)
print('Accuracy over the test set 4: \n ', round((score[1]*100), 2), '%')
score = model5.evaluate(X_test5, y_test5, verbose=0)
print('Accuracy over the test set 5: \n ', round((score[1]*100), 2), '%')
score = model6.evaluate(X_test6, y_test6, verbose=0)
print('Accuracy over the test set 6: \n ', round((score[1]*100), 2), '%')
score = model7.evaluate(X_test7, y_test7, verbose=0)
print('Accuracy over the test set 7: \n ', round((score[1]*100), 2), '%')
score = model8.evaluate(X_test8, y_test8, verbose=0)
print('Accuracy over the test set 8: \n ', round((score[1]*100), 2), '%')
